{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59299aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovanni/.virtualenvs/news_clf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d53977",
   "metadata": {},
   "source": [
    "Due to the fact that this is an initial test without using article, we don't care about missing article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0028381b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning shapes: \n",
      "Xtr_val: (63997, 5) | X_test: (16000, 5) | ytr_val: (63997,) | y_test: (16000,)\n",
      "> \u001b[32m/home/giovanni/Projects/universita/NewsClassifier/src/preprocessing.py\u001b[39m(\u001b[92m159\u001b[39m)\u001b[36mfull_prep\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m    157\u001b[39m \n",
      "\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mimport\u001b[39;00m pdb;pdb.set_trace()\n",
      "\u001b[32m--> 159\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m X, idxs\n",
      "\u001b[32m    160\u001b[39m \n",
      "\u001b[32m    161\u001b[39m \n",
      "\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 663603 stored elements and shape (63996, 6666)>\n"
     ]
    }
   ],
   "source": [
    "results, hyperparams = evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4525ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Fbeta</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear_svm</th>\n",
       "      <td>0.638337</td>\n",
       "      <td>0.608072</td>\n",
       "      <td>0.608754</td>\n",
       "      <td>0.639687</td>\n",
       "      <td>0.608754</td>\n",
       "      <td>56.303683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.646505</td>\n",
       "      <td>0.613239</td>\n",
       "      <td>0.626804</td>\n",
       "      <td>0.647875</td>\n",
       "      <td>0.626804</td>\n",
       "      <td>605.965896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Precision    Recall     Fbeta  Accuracy  f1-macro        time\n",
       "linear_svm   0.638337  0.608072  0.608754  0.639687  0.608754   56.303683\n",
       "xgboost      0.646505  0.613239  0.626804  0.647875  0.626804  605.965896"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad75d61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear_svm': {'C': 9.730107134041818, 'max_iter': 5000},\n",
       " 'xgboost': {'objective': 'multi:softprob',\n",
       "  'num_class': 7,\n",
       "  'eval_metric': 'mlogloss',\n",
       "  'tree_method': 'hist',\n",
       "  'n_jobs': -1,\n",
       "  'learning_rate': 0.16807482826479683,\n",
       "  'n_estimators': 500,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 5,\n",
       "  'subsample': 0.8,\n",
       "  'colsample_bytree': 0.6,\n",
       "  'gamma': 0.0,\n",
       "  'reg_alpha': 0.0,\n",
       "  'reg_lambda': 1.0}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ee1c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic_regression': {'solver': 'saga',\n",
       "  'l1_ratio': 0,\n",
       "  'C': 7.064102061998609,\n",
       "  'max_iter': 5000},\n",
       " 'naive_bayes': {'alpha': 0.10292465492640979},\n",
       " 'xgboost': {'objective': 'multi:softprob',\n",
       "  'num_class': 7,\n",
       "  'eval_metric': 'mlogloss',\n",
       "  'tree_method': 'hist',\n",
       "  'n_jobs': -1,\n",
       "  'learning_rate': 0.1241198606157316,\n",
       "  'n_estimators': 800,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 1,\n",
       "  'subsample': 0.8,\n",
       "  'colsample_bytree': 0.6,\n",
       "  'gamma': 0.0,\n",
       "  'reg_alpha': 0.0,\n",
       "  'reg_lambda': 1.0},\n",
       " 'linear_svm': {'C': 0.4213625248742607, 'max_iter': 5000}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1789054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovanni/.virtualenvs/news_clf/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [14:14:58] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"linear_svm\", \"xgboost\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction saved in submissions_v2.csv\n"
     ]
    }
   ],
   "source": [
    "{'linear_svm': {'C': 9.730107134041818, 'max_iter': 5000},\n",
    " 'xgboost': {'objective': 'multi:softprob',\n",
    "  'num_class': 7,\n",
    "  'eval_metric': 'mlogloss',\n",
    "  'tree_method': 'hist',\n",
    "  'n_jobs': -1,\n",
    "  'learning_rate': 0.16807482826479683,\n",
    "  'n_estimators': 500,\n",
    "  'max_depth': 5,\n",
    "  'min_child_weight': 5,\n",
    "  'subsample': 0.8,\n",
    "  'colsample_bytree': 0.6,\n",
    "  'gamma': 0.0,\n",
    "  'reg_alpha': 0.0,\n",
    "  'reg_lambda': 1.0}}\n",
    "\n",
    "produce_submissions('xgboost', hyperparams, 'submissions_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8fe0f",
   "metadata": {},
   "source": [
    "This results of the first baseline show:\n",
    "- this kind of approach is promising, so it's a good idea to continue to work in this direction\n",
    "- xgboost looks like the best model, so I will keep it even if it's quite time consuming\n",
    "- logistic_regression it's the most time consuming and also the worst, so I will not use it (at least in the middle experiments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news_clf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
