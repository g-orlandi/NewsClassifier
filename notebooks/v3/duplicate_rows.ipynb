{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b406e0d7",
   "metadata": {},
   "source": [
    "## DUPLICATES\n",
    "\n",
    "(https://www.clrn.org/how-to-handle-duplicate-data-in-machine-learning/)\n",
    "\n",
    "From this first analysis:\n",
    "\n",
    "- development set\n",
    "  - duplicate rows: 1559\n",
    "  - NaN article col: 1875\n",
    "- evaluation set\n",
    "  - dupliacte rows: 96\n",
    "  - NaN article col: 449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76fae8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import Preprocessor\n",
    "from src.config import *\n",
    "from src.preprocessing import *\n",
    "from src.utils import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "news_df = load_data(DEVELOPMENT_PATH)\n",
    "news_df['title'] = Preprocessor.clean_text(news_df['title'])\n",
    "news_df['article'] = Preprocessor.clean_text(news_df['article'])\n",
    "news_df.loc[news_df['article'].str.len() < 5, \"article\"] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11d56ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source        294\n",
       "title           1\n",
       "article      1887\n",
       "page_rank       0\n",
       "timestamp       0\n",
       "y               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af72ae7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Deduplication rules.\n",
    "Records are grouped at content level using (article, title).\n",
    "\n",
    "- (article, title) with different target labels (y) → drop entire cluster\n",
    "- (article, title, y) identical → collapse records into a single instance, aggregating metadata as follows:\n",
    "  - source → unique non-null list of sources\n",
    "  -  page_rank → median value across observations\n",
    "  -  timestamp → single representative value earliest\n",
    "\n",
    "This procedure removes spurious duplicates while preserving informative metadata variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "810713e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79997, 6)\n",
      "(76462, 6)\n"
     ]
    }
   ],
   "source": [
    "conflict_idx = (\n",
    "    news_df.groupby(['article'])['y']\n",
    "          .transform('nunique')\n",
    "          .gt(1)\n",
    ")\n",
    "print(news_df.shape)\n",
    "news_df.drop(index=news_df.index[conflict_idx], inplace=True)\n",
    "print(news_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822bf8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72742, 7)\n",
      "(71947, 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "keys = ['article', 'y']\n",
    "\n",
    "ts = news_df[\"timestamp\"].replace(\"0000-00-00 00:00:00\", pd.NA)\n",
    "ts = pd.to_datetime(ts, errors=\"coerce\")  # invalid -> NaT\n",
    "news_df[\"timestamp\"] = ts\n",
    "\n",
    "dup_mask = news_df.duplicated(subset=keys, keep=False)\n",
    "groups = news_df.loc[dup_mask].groupby(keys, dropna=False)\n",
    "\n",
    "updates = {}          # keep_idx -> dict colonne aggiornate\n",
    "to_drop = []          # indici da droppare\n",
    "\n",
    "for (article, y), g in groups:\n",
    "    keep_idx = g.index[0]\n",
    "    drop_idxs = g.index[1:]\n",
    "    to_drop.extend(drop_idxs)\n",
    "\n",
    "    src_nonnull = g['source'].dropna().astype(str).unique()\n",
    "    src_nonnull = sorted(src_nonnull)\n",
    "\n",
    "    # se c'è una sola source reale, la metto in 'source' e lascio 'sources' a NaN\n",
    "    if len(src_nonnull) == 1:\n",
    "        source = src_nonnull[0]\n",
    "        sources = pd.NA\n",
    "    else:\n",
    "        source = pd.NA\n",
    "        sources = src_nonnull  # lista (senza NaN)\n",
    "\n",
    "    ts = g['timestamp'].dropna()\n",
    "    timestamp = ts.min() if not ts.empty else pd.NaT\n",
    "\n",
    "    updates[keep_idx] = {\n",
    "        'timestamp': timestamp,        \n",
    "        'page_rank': g['page_rank'].median().round().astype('int'),\n",
    "        'source': source,\n",
    "        'sources': sources,\n",
    "        'title': g.loc[g['title'].str.len().idxmax(), 'title']\n",
    "    }\n",
    "\n",
    "# crea colonna 'sources' se non esiste\n",
    "if 'sources' not in news_df.columns:\n",
    "    news_df['sources'] = pd.NA\n",
    "\n",
    "# applica update sulle righe tenute\n",
    "updates_df = pd.DataFrame.from_dict(updates, orient='index')\n",
    "news_df.loc[updates_df.index, updates_df.columns] = updates_df\n",
    "\n",
    "# droppa le righe duplicate \"in eccesso\"\n",
    "news_df.drop(index=to_drop, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "keys = ['title', 'y']\n",
    "\n",
    "dup_mask = news_df.duplicated(subset=keys, keep=False)\n",
    "groups = news_df.loc[dup_mask].groupby(keys, dropna=False)\n",
    "\n",
    "updates = {}          # keep_idx -> dict colonne aggiornate\n",
    "to_drop = []          # indici da droppare\n",
    "\n",
    "for (title, y), g in groups:\n",
    "    keep_idx = g.index[0]\n",
    "    drop_idxs = g.index[1:]\n",
    "    to_drop.extend(drop_idxs)\n",
    "\n",
    "    src_nonnull = g['source'].dropna().astype(str).unique()\n",
    "    src_nonnull = sorted(src_nonnull)\n",
    "\n",
    "    # se c'è una sola source reale, la metto in 'source' e lascio 'sources' a NaN\n",
    "    if len(src_nonnull) == 1:\n",
    "        source = src_nonnull[0]\n",
    "        sources = pd.NA\n",
    "    else:\n",
    "        source = pd.NA\n",
    "        sources = src_nonnull  # lista (senza NaN)\n",
    "\n",
    "    ts = g['timestamp'].dropna()\n",
    "    timestamp = ts.min() if not ts.empty else pd.NaT\n",
    "\n",
    "    updates[keep_idx] = {\n",
    "        'timestamp': timestamp,        \n",
    "        'page_rank': g['page_rank'].median().round().astype('int'),\n",
    "        'source': source,\n",
    "        'sources': sources,\n",
    "        'article': g.loc[g['article'].str.len().idxmax(), 'article']\n",
    "    }\n",
    "\n",
    "# crea colonna 'sources' se non esiste\n",
    "if 'sources' not in news_df.columns:\n",
    "    news_df['sources'] = pd.NA\n",
    "\n",
    "# applica update sulle righe tenute\n",
    "updates_df = pd.DataFrame.from_dict(updates, orient='index')\n",
    "news_df.loc[updates_df.index, updates_df.columns] = updates_df\n",
    "\n",
    "# droppa le righe duplicate \"in eccesso\"\n",
    "news_df.drop(index=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72840ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source         374\n",
       "title            0\n",
       "article          6\n",
       "page_rank        0\n",
       "timestamp    24253\n",
       "y                0\n",
       "sources      71015\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news_clf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
